{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab6568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on Udemy lecture with custom modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bf1e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa047348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below commands are required if doing for the first time\n",
    "# Outputs are included here as a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "482c4026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "    \u001b[93mInfo about spaCy\u001b[0m\r\n",
      "\r\n",
      "    spaCy version      2.0.16         \r\n",
      "    Location           /opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy\r\n",
      "    Platform           Darwin-19.6.0-x86_64-i386-64bit\r\n",
      "    Python version     3.7.13         \r\n",
      "    Models                            \r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f029c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz#egg=en_core_web_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.0.0/en_core_web_sm-2.0.0.tar.gz (37.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 37.4MB 89.0MB/s ta 0:00:011  14% |████▌                           | 5.3MB 21.9MB/s eta 0:00:02██████████▏ | 35.2MB 12.1MB/s eta 0:00:01�███████████ | 36.2MB 13.7MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "  Running setup.py install for en-core-web-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed en-core-web-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/en_core_web_sm\n",
      "    -->\n",
      "    /opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/spacy/data/en\n",
      "\n",
      "    You can now load the model via spacy.load('en')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540a8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')  # a small core English library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baac7acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Musk is looking at buying U.S. Twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb712bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Musk 91 NOUN\n",
      "is 99 VERB\n",
      "looking 99 VERB\n",
      "at 84 ADP\n",
      "buying 99 VERB\n",
      "U.S. 95 PROPN\n",
      "Twitter 91 NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a8cd3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nsubj\n",
      "aux\n",
      "ROOT\n",
      "prep\n",
      "pcomp\n",
      "compound\n",
      "dobj\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.dep_) # syntactic dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2cf66b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.Tagger at 0x7fc6ba6c8850>),\n",
       " ('parser', <spacy.pipeline.DependencyParser at 0x7fc6ba79a350>),\n",
       " ('ner', <spacy.pipeline.EntityRecognizer at 0x7fc6ba79a8f0>)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa290410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe531d6",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "024579a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Startups are evaluating hiring more carefully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f63675fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Startups NOUN nsubj\n",
      "are VERB aux\n",
      "evaluating VERB ROOT\n",
      "hiring VERB xcomp\n",
      "more ADV advmod\n",
      "carefully ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(token.text, token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5635242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Startups"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c9d608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NOUN'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88c31ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sentences from TechCrunch\n",
    "article = nlp(u\"Following a preview in April, Microsoft this morning announced the general availability of virtual machines (VMs) on Azure featuring the Ampere Altra, a processor based on the Arm architecture. The first Azure VMs powered by Arm chips, Microsoft says that they’re accessible in 10 Azure regions today and can be included in Kubernetes clusters managed using Azure Kubernetes Service beginning on September 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f927afe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Azure featuring the Ampere Altra, a processor based on the Arm architecture. The first Azure VMs powered by"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article[20:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc8bbfa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article[20:40]) # note that this is a Span data type\n",
    "# Span is defined as: A slice from a Doc object.\n",
    "# URL: https://spacy.io/api/span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "068c1403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "863761f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following a preview in April, Microsoft this morning announced the general availability of virtual machines (VMs) on Azure featuring the Ampere Altra, a processor based on the Arm architecture.\n",
      "The first Azure VMs powered by Arm chips, Microsoft says that they’re accessible in 10 Azure regions today and can be included in Kubernetes clusters managed using Azure Kubernetes Service beginning on September 1.\n"
     ]
    }
   ],
   "source": [
    "for sentence in article.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca8146d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mystring = '\"We\\'re moving to L.A.!\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2f448d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eb78575",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1417b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "We\n",
      "'re\n",
      "moving\n",
      "to\n",
      "L.A.\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6739fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_string = nlp(u\"We're here to help! Our email is username@company.com! Or visit www.companywebsite.info!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e5fed6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We\n",
      "'re\n",
      "here\n",
      "to\n",
      "help\n",
      "!\n",
      "Our\n",
      "email\n",
      "is\n",
      "username@company.com\n",
      "!\n",
      "Or\n",
      "visit\n",
      "www.companywebsite.info\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for t in new_string:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b95fa48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a68d61a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.vocab.Vocab at 0x7fc6b83c9440>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_string.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3e2f174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57852"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_string.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fb991e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We~'re~here~to~help~!~Our~email~is~username@company.com~!~Or~visit~www.companywebsite.info~!~"
     ]
    }
   ],
   "source": [
    "for t in new_string:\n",
    "    print(t.text,end='~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a3b8279",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entity in new_string.ents:\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd2e8317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try another sentence\n",
    "car_string = nlp(u\"Johnny wanted to buy Ford for $10,000 but his girlfriend Claire said he should buy Volvo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79e83312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnny PERSON People, including fictional\n",
      "Ford ORG Companies, agencies, institutions, etc.\n",
      "10,000 MONEY Monetary values, including unit\n",
      "Claire PERSON People, including fictional\n",
      "Volvo ORG Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "for entity in car_string.ents:\n",
    "    print(entity, entity.label_, spacy.explain(entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78172b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnny\n",
      "Ford\n",
      "his girlfriend\n",
      "Claire\n",
      "he\n",
      "Volvo\n"
     ]
    }
   ],
   "source": [
    "for chunk in car_string.noun_chunks:\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "683bb7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "39af696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Samsung invested in a new U.S. factory in TX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "773c6ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"860\" height=\"317.0\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Samsung</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">invested</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">new</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">U.S.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">factory</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">TX</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,137.0 125.0,137.0 125.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M215.0,184.0 L223.0,172.0 207.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M340,182.0 C340,47.0 585.0,47.0 585.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M430,182.0 C430,92.0 580.0,92.0 580.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,137.0 575.0,137.0 575.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-5\" stroke-width=\"2px\" d=\"M250,182.0 C250,2.0 590.0,2.0 590.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-5\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M590.0,184.0 L598.0,172.0 582.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-6\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-6\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M665.0,184.0 L673.0,172.0 657.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-7\" stroke-width=\"2px\" d=\"M700,182.0 C700,137.0 755.0,137.0 755.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-7\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M755.0,184.0 L763.0,172.0 747.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='dep',jupyter=True,options={'distance':90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2da559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u\"Facebook is considering to expand into Metaverse in next several years.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "810f573e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Facebook\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is considering to expand into \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Metaverse\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    next several years\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc,style='ent',jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c19d434",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f4f32f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4fa312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a372ef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "78842a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','ran','running','hardened','easier', 'easily']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "677de9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run---->run\n",
      "runner---->runner\n",
      "ran---->ran\n",
      "running---->run\n",
      "hardened---->harden\n",
      "easier---->easier\n",
      "easily---->easili\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + '---->' + p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02e68e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e30b292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69d609c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ---->run\n",
      "runner ---->runner\n",
      "ran ---->ran\n",
      "running ---->run\n",
      "hardened ---->harden\n",
      "easier ---->easier\n",
      "easily ---->easili\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + ' ---->' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed1e9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2 = ['generous','generation','generously','thankful','thank','thankless']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aae2a3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generous ---->generous\n",
      "generation ---->generat\n",
      "generously ---->generous\n",
      "thankful ---->thank\n",
      "thank ---->thank\n",
      "thankless ---->thankless\n"
     ]
    }
   ],
   "source": [
    "for word in word2:\n",
    "    print(word + ' ---->' + s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc0090",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4d04e79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(u\"I'm a swimmer in the swim race because I enjoy swimming and have been swimming for a long time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5ff54f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 561228191312463089 -PRON-\n",
      "'m \t VERB \t 10382539506755952630 be\n",
      "a \t DET \t 11901859001352538922 a\n",
      "swimmer \t NOUN \t 8984364056738817612 swimmer\n",
      "in \t ADP \t 3002984154512732771 in\n",
      "the \t DET \t 7425985699627899538 the\n",
      "swim \t NOUN \t 13054409096476681252 swim\n",
      "race \t NOUN \t 8048469955494714898 race\n",
      "because \t ADP \t 16950148841647037698 because\n",
      "I \t PRON \t 561228191312463089 -PRON-\n",
      "enjoy \t VERB \t 13716726989081948958 enjoy\n",
      "swimming \t VERB \t 13054409096476681252 swim\n",
      "and \t CCONJ \t 2283656566040971221 and\n",
      "have \t VERB \t 14692702688101715474 have\n",
      "been \t VERB \t 10382539506755952630 be\n",
      "swimming \t VERB \t 13054409096476681252 swim\n",
      "for \t ADP \t 16037325823156266367 for\n",
      "a \t DET \t 11901859001352538922 a\n",
      "long \t ADJ \t 12965068231793614765 long\n",
      "time \t NOUN \t 8885804376230376864 time\n",
      ". \t PUNCT \t 12646065887601541794 .\n"
     ]
    }
   ],
   "source": [
    "for token in doc1:\n",
    "    print(token.text,'\\t',token.pos_,'\\t',token.lemma, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0485f3e",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "74ebd924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'enough', 'not', 'sixty', 'wherein', 'even', 'across', 'fifty', 'hereby', 'make', 'due', 'once', 'others', 'our', 'because', 'whereupon', 'about', 'hence', 'see', 'call', 'these', 'throughout', 'twelve', 'we', 'when', 'had', 'using', 'whose', 'afterwards', 'been', 'herself', 'until', 'to', 'in', 'under', 'via', 'side', 'below', 'former', 'already', 'therefore', 'amongst', 'else', 'down', 'himself', 'other', 'unless', 'yet', 'what', 'anything', 'ca', 're', 'hundred', 'yourself', 'another', 'why', 'out', 'otherwise', 'whatever', 'least', 'now', 'seemed', 'themselves', 'three', 'thus', 'both', 'take', 'amount', 'each', 'eight', 'thereupon', 'since', 'nevertheless', 'elsewhere', 'alone', 'with', 'thru', 'more', 'within', 'anywhere', 'somehow', 'become', 'anyone', 'last', 'can', 'onto', 'really', 'six', 'should', 'too', 'name', 'never', 'noone', 'his', 'seems', 'if', 'whence', 'eleven', 'yours', 'cannot', 'whereby', 'which', 'also', 'someone', 'none', 'have', 'am', 'two', 'was', 'put', 'several', 'is', 'therein', 'toward', 'top', 'myself', 'done', 'so', 'neither', 'beforehand', 'thence', 'some', 'whenever', 'made', 'are', 'please', 'no', 'first', 'regarding', 'only', 'you', 'must', 'them', 'or', 'go', 'who', 'how', 'most', 'every', 'above', 'indeed', 'be', 'whom', 'yourselves', 'us', 'will', 'your', 'rather', 'has', 'hereafter', 'thereby', 'besides', 'she', 'just', 'per', 'from', 'all', 'for', 'around', 'forty', 'over', 'say', 'whereas', 'this', 'any', 'four', 'fifteen', 'along', 'sometimes', 'among', 'ours', 'but', 'often', 'without', 'anyway', 'move', 'mine', 'sometime', 'hers', 'hereupon', 'were', 'moreover', 'one', 'keep', 'although', 'empty', 'formerly', 'could', 'latterly', 'becoming', 'of', 'the', 'he', 'again', 'whoever', 'except', 'would', 'next', 'still', 'up', 'however', 'then', 'front', 'here', 'than', 'seeming', 'almost', 'those', 'that', 'wherever', 'whither', 'it', 'there', 'few', 'together', 'on', 'such', 'quite', 'may', 'perhaps', 'though', 'at', 'her', 'show', 'thereafter', 'as', 'very', 'behind', 'beside', 'my', 'nowhere', 'various', 'an', 'whereafter', 'same', 'used', 'many', 'anyhow', 'doing', 'ten', 'its', 'twenty', 'becomes', 'full', 'i', 'before', 'their', 'much', 'give', 'everything', 'towards', 'part', 'might', 'upon', 'latter', 'did', 'him', 'beyond', 'namely', 'nor', 'nothing', 'own', 'against', 'nine', 'something', 'whether', 'after', 'by', 'me', 'do', 'five', 'ever', 'well', 'through', 'get', 'itself', 'and', 'everyone', 'ourselves', 'serious', 'does', 'somewhere', 'being', 'seem', 'back', 'mostly', 'a', 'either', 'where', 'between', 'while', 'further', 'less', 'nobody', 'bottom', 'third', 'whole', 'everywhere', 'off', 'they', 'during', 'into', 'always', 'became', 'herein', 'meanwhile'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aceba872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['is'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bc853854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['Awesome'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b02aee7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.add('rly') # adding 'rly' to the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ad1ad94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['rly'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ea576883",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.Defaults.stop_words.remove('rly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d4b25d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['rly'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "174a3c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['rly'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb0f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
