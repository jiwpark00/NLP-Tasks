{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f8a32fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Udemy project but extended for more experimentation and investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecbbb19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "quora = pd.read_csv('quora_questions.csv') # Example dataset used in the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b4b7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404289 entries, 0 to 404288\n",
      "Data columns (total 1 columns):\n",
      "Question    404289 non-null object\n",
      "dtypes: object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "quora.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b7a2ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question\n",
       "0  What is the step by step guide to invest in sh...\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...\n",
       "2  How can I increase the speed of my internet co...\n",
       "3  Why am I mentally very lonely? How can I solve...\n",
       "4  Which one dissolve in water quikly sugar, salt..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e3d770c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp_course/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "# Dependencies\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9c7cad",
   "metadata": {},
   "source": [
    "## Basic case - just default cv and 10 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31020436",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.9, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ef02382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# countVec - countvectorizer\n",
    "# n - number of components\n",
    "\n",
    "def LDA_generator(countVec, n):\n",
    "    dtm = countVec.fit_transform(quora['Question'])\n",
    "    # initialize LDA\n",
    "    LDA = LatentDirichletAllocation(n_components=n,random_state=42)\n",
    "    LDA.fit(dtm)\n",
    "    return LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "099117fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_basic = LDA_generator(cv,10) # this takes a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5062dd5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=10, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c52df994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_generator(LDA,countVec):\n",
    "    # Now, we can do this for each topoic\n",
    "    for i, topic in enumerate(LDA.components_):\n",
    "        print(f\"The TOP 10 words for each topic #{i}\")\n",
    "        print([countVec.get_feature_names()[index] for index in topic.argsort()[-10:]])\n",
    "        print('\\n')\n",
    "        print('\\n')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716c7859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TOP 10 words for each topic #0\n",
      "['android', 'good', 'career', 'google', 'difference', 'software', 'engineering', 'examples', 'best', 'does']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #1\n",
      "['rs', 'india', 'think', 'english', 'black', 'stop', 'indian', '1000', 'notes', '500']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #2\n",
      "['universe', 'compare', 'water', 'did', 'average', 'energy', 'good', 'time', 'does', 'life']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #3\n",
      "['ask', 'day', 'question', 'movie', 'things', 'questions', 'know', 'new', 'people', 'quora']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #4\n",
      "['women', 'country', 'differences', 'rid', 'password', 'college', 'difference', 'car', 'india', 'job']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #5\n",
      "['war', 'work', 'sex', 'long', 'did', 'feel', 'mean', 'world', 'like', 'does']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #6\n",
      "['days', 'difference', 'school', 'science', 'study', 'live', 'good', 'lose', 'weight', 'best']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #7\n",
      "['donald', 'start', 'india', 'make', 'online', 'trump', 'money', 'learn', 'way', 'best']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #8\n",
      "['number', 'love', 'website', 'free', 'phone', 'data', 'instagram', 'facebook', 'use', 'account']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #9\n",
      "['police', 'did', 'test', 'age', 'increase', 'possible', 'time', 'year', 'old', 'years']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_generator(LDA_basic,cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa3ddb8",
   "metadata": {},
   "source": [
    "## More components but greatly reducing the number of words based on frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4be08f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_2 = CountVectorizer(max_df=0.9, min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0899b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA_2 = LDA_generator(cv_2,20) # this takes a while to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48cb772d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=10, mean_change_tol=0.001,\n",
       "             n_components=20, n_jobs=None, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eedc39c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The TOP 10 words for each topic #0\n",
      "['boyfriend', 'friend', 'guy', 'like', 'big', 'effects', 'girlfriend', 'high', 'iphone', 'person']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #1\n",
      "['universities', 'looking', 'india', 'new', 'does', 'earn', 'online', 'money', 'difference', 'make']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #2\n",
      "['parents', 'china', 'like', 'education', 'programming', 'website', 'language', 'relationship', 'india', 'indian']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #3\n",
      "['video', 'hair', 'laptop', 'good', 'phone', 'free', 'buy', 'way', 'learn', 'best']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #4\n",
      "['living', 'usa', 'purpose', 'war', 'happen', 'good', 'pakistan', 'meaning', 'india', 'life']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #5\n",
      "['fall', 'terms', 'getting', 'state', 'better', 'differences', 'chinese', 'friends', 'school', 'love']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #6\n",
      "['sentence', 'bad', 'card', 'history', 'average', 'social', 'word', 'examples', 'used', 'use']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #7\n",
      "['india', 'win', 'hillary', 'country', 'clinton', 'president', 'think', 'donald', 'trump', 'people']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #8\n",
      "['10', 'days', 'password', 'number', 'year', 'account', 'years', 'facebook', 'instagram', 'old']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #9\n",
      "['read', 'exam', 'prepare', 'books', 'business', 'improve', '2016', 'english', 'start', 'best']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #10\n",
      "['worst', 'control', 'hotel', 'safe', 'stop', 'police', 'god', 'modi', 'thing', 'did']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #11\n",
      "['light', 'earth', 'feel', 'cost', 'water', 'long', 'like', 'work', 'mean', 'does']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #12\n",
      "['tv', 'whatsapp', 'university', 'career', 'job', 'science', 'computer', 'study', 'student', 'engineering']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #13\n",
      "['travel', 'girl', 'going', 'don', 'possible', 'new', 'day', 'things', 'know', 'time']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #14\n",
      "['government', 'companies', 'data', 'rs', 'black', 'india', 'app', '1000', 'notes', '500']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #15\n",
      "['management', 'service', 'jobs', 'experience', 'best', 've', 'software', 'feel', 'like', 'sex']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #16\n",
      "['job', 'like', 'girls', 'men', 'com', 'women', 'best', 'movies', 'movie', 'world']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #17\n",
      "['center', 'alcohol', 'advantages', 'account', 'problem', 'code', 'power', 'math', 'bank', 'car']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #18\n",
      "['fat', 'human', 'body', 'eat', 'food', 'ways', 'best', 'lose', 'weight', 'way']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The TOP 10 words for each topic #19\n",
      "['asked', 'answers', 'answer', 'different', 'ask', 'people', 'google', 'question', 'questions', 'quora']\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topic_generator(LDA_2,cv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3336a63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, highlighting a keyword or two/summary\n",
    "topic_categorization_dict = {0: 'Relationship', 1: 'Earning', 2: 'Education',\\\n",
    "                             3: 'Internet Search', 4: 'Purpose', 5: 'Fall Semester', 6: 'History',\\\n",
    "                            7: 'Politics', 8: 'Social Network', 9: 'Business', 10: 'Safety',\\\n",
    "                            11: 'Essentials', 12: 'Networks', 13: 'Travel', 14: 'Corporations',\\\n",
    "                            15: 'Management', 16: 'Dating', 17: 'Wealth', 18: 'Weight Loss',\\\n",
    "                            19: 'Questions'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2eecaaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Topic Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>4</td>\n",
       "      <td>Purpose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>9</td>\n",
       "      <td>Business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>3</td>\n",
       "      <td>Internet Search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>1</td>\n",
       "      <td>Earning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>3</td>\n",
       "      <td>Internet Search</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  Topic      Topic Label\n",
       "0  What is the step by step guide to invest in sh...      4          Purpose\n",
       "1  What is the story of Kohinoor (Koh-i-Noor) Dia...      9         Business\n",
       "2  How can I increase the speed of my internet co...      3  Internet Search\n",
       "3  Why am I mentally very lonely? How can I solve...      1          Earning\n",
       "4  Which one dissolve in water quikly sugar, salt...      3  Internet Search"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quora['Topic Label'] = quora['Topic'].map(topic_categorization_dict)\n",
    "quora.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bed11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
