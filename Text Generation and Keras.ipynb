{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc855384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from Udemy lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0679dfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "    \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "403912fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8af11bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en',disable=['parser','tagger','ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c9d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c232e288",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75da507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1853786",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d878642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f233156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11394"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdf72aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# send 25 words and have the network predict 26th word\n",
    "train_len = 25 + 1\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len,len(tokens)):\n",
    "    seq = tokens[i-train_len:i]\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d628957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just sanity check\n",
    "# when i = 26 (the first value)\n",
    "# i-train_len --> 0\n",
    "# i --> 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f3e87ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4b0e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One word over\n",
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48b65868",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab89e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4632307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[964,\n",
       " 14,\n",
       " 265,\n",
       " 51,\n",
       " 263,\n",
       " 416,\n",
       " 87,\n",
       " 222,\n",
       " 129,\n",
       " 111,\n",
       " 962,\n",
       " 262,\n",
       " 50,\n",
       " 43,\n",
       " 37,\n",
       " 321,\n",
       " 7,\n",
       " 23,\n",
       " 555,\n",
       " 3,\n",
       " 150,\n",
       " 261,\n",
       " 6,\n",
       " 2704,\n",
       " 14,\n",
       " 24]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78cf1b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964 : call\n",
      "14 : me\n",
      "265 : ishmael\n",
      "51 : some\n",
      "263 : years\n",
      "416 : ago\n",
      "87 : never\n",
      "222 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "962 : precisely\n",
      "262 : having\n",
      "50 : little\n",
      "43 : or\n",
      "37 : no\n",
      "321 : money\n",
      "7 : in\n",
      "23 : my\n",
      "555 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "261 : particular\n",
      "6 : to\n",
      "2704 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "# Translating above first sequence into the words\n",
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1ab5e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2709\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)\n",
    "print(vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db067cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,   14,  265, ..., 2704,   14,   24],\n",
       "       [  14,  265,   51, ...,   14,   24,  965],\n",
       "       [ 265,   51,  263, ...,   24,  965,    5],\n",
       "       ...,\n",
       "       [ 960,   12,  168, ...,  264,   53,    2],\n",
       "       [  12,  168, 2703, ...,   53,    2, 2709],\n",
       "       [ 168, 2703,    3, ...,    2, 2709,   26]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "sequences = np.array(sequences)\n",
    "sequences # now as numpy array instead of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3863bae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,   14,  265, ...,    6, 2704,   14],\n",
       "       [  14,  265,   51, ..., 2704,   14,   24],\n",
       "       [ 265,   51,  263, ...,   14,   24,  965],\n",
       "       ...,\n",
       "       [ 960,   12,  168, ...,   11,  264,   53],\n",
       "       [  12,  168, 2703, ...,  264,   53,    2],\n",
       "       [ 168, 2703,    3, ...,   53,    2, 2709]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "sequences[:,:-1] # all rows and all columns except last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3094656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  24,  965,    5, ...,    2, 2709,   26])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5795f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a363a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y,num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5af08648",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "069dcfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11368, 25)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e9d0906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Embedding\n",
    "\n",
    "def create_model(vocabulary_size,seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocabulary_size,output_dim=seq_len,input_length=seq_len))\n",
    "    model.add(LSTM(100,return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(100,activation='relu'))\n",
    "    model.add(Dense(vocabulary_size,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',\\\n",
    "                 metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7653801",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-30 16:43:09.623270: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 25, 25)            67750     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 25, 100)           50400     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2710)              273710    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 482,360\n",
      "Trainable params: 482,360\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1,seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1606d62",
   "metadata": {},
   "source": [
    "### Increased training period to 30 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0338cde6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "89/89 [==============================] - 7s 78ms/step - loss: 6.0253 - accuracy: 0.0540\n",
      "Epoch 2/30\n",
      "89/89 [==============================] - 7s 80ms/step - loss: 5.9161 - accuracy: 0.0606\n",
      "Epoch 3/30\n",
      "89/89 [==============================] - 7s 82ms/step - loss: 5.8372 - accuracy: 0.0656\n",
      "Epoch 4/30\n",
      "89/89 [==============================] - 7s 82ms/step - loss: 5.7555 - accuracy: 0.0659\n",
      "Epoch 5/30\n",
      "89/89 [==============================] - 7s 75ms/step - loss: 5.6840 - accuracy: 0.0701\n",
      "Epoch 6/30\n",
      "89/89 [==============================] - 7s 75ms/step - loss: 5.6341 - accuracy: 0.0725\n",
      "Epoch 7/30\n",
      "89/89 [==============================] - 7s 77ms/step - loss: 5.5765 - accuracy: 0.0720\n",
      "Epoch 8/30\n",
      "89/89 [==============================] - 7s 75ms/step - loss: 5.5267 - accuracy: 0.0761\n",
      "Epoch 9/30\n",
      "89/89 [==============================] - 7s 76ms/step - loss: 5.4793 - accuracy: 0.0791\n",
      "Epoch 10/30\n",
      "89/89 [==============================] - 7s 75ms/step - loss: 5.4318 - accuracy: 0.0812\n",
      "Epoch 11/30\n",
      "89/89 [==============================] - 7s 75ms/step - loss: 5.3857 - accuracy: 0.0816\n",
      "Epoch 12/30\n",
      "89/89 [==============================] - 7s 76ms/step - loss: 5.3469 - accuracy: 0.0848\n",
      "Epoch 13/30\n",
      "89/89 [==============================] - 7s 78ms/step - loss: 5.3019 - accuracy: 0.0863\n",
      "Epoch 14/30\n",
      "89/89 [==============================] - 7s 78ms/step - loss: 5.2627 - accuracy: 0.0865\n",
      "Epoch 15/30\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 5.2271 - accuracy: 0.0889\n",
      "Epoch 16/30\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 5.1864 - accuracy: 0.0874\n",
      "Epoch 17/30\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 5.1484 - accuracy: 0.0895\n",
      "Epoch 18/30\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 5.1133 - accuracy: 0.0921\n",
      "Epoch 19/30\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 5.0732 - accuracy: 0.0903\n",
      "Epoch 20/30\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 5.0415 - accuracy: 0.0928\n",
      "Epoch 21/30\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 5.0031 - accuracy: 0.0928\n",
      "Epoch 22/30\n",
      "89/89 [==============================] - 8s 91ms/step - loss: 4.9671 - accuracy: 0.0962\n",
      "Epoch 23/30\n",
      "89/89 [==============================] - 9s 96ms/step - loss: 4.9298 - accuracy: 0.0953\n",
      "Epoch 24/30\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 4.8957 - accuracy: 0.0992\n",
      "Epoch 25/30\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 4.8537 - accuracy: 0.1015\n",
      "Epoch 26/30\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 4.8165 - accuracy: 0.1023\n",
      "Epoch 27/30\n",
      "89/89 [==============================] - 8s 94ms/step - loss: 4.7821 - accuracy: 0.1036\n",
      "Epoch 28/30\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 4.7388 - accuracy: 0.1079\n",
      "Epoch 29/30\n",
      "89/89 [==============================] - 8s 93ms/step - loss: 4.6991 - accuracy: 0.1080\n",
      "Epoch 30/30\n",
      "89/89 [==============================] - 8s 92ms/step - loss: 4.6542 - accuracy: 0.1100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc201ebed0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pickle import dump,load\n",
    "\n",
    "model.fit(X,y,batch_size=128,epochs=30,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ca58de0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_mobydick_model_08302022.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d99567ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer,open('my_simpletokenizer_08302022','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e7fc8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "781f2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,tokenizer,seq_len,seed_text,num_gen_words):\n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        # make sure if it's 25\n",
    "        pad_encoded = pad_sequences([encoded_text],maxlen=seq_len,truncating='pre')\n",
    "        \n",
    "        pred_word_ind = np.argmax(model.predict(pad_encoded,verbose=0)[0], axis=-1)\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        \n",
    "        input_text += ' '+pred_word # this is for prediction purposes\n",
    "        \n",
    "        output_text.append(pred_word) # this is for actual output\n",
    "    \n",
    "    \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9f868df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d8dcbdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(101)\n",
    "random_pick = random.randint(0,len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "259223da",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text = text_sequences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dd9b50e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and throwing the clothes to one side he really did this in not only a civil but a really kind and charitable way i stood looking'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = ' '.join(random_seed_text)\n",
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1a653975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'up the counterpane and a harpooneer and a whale and be be be be be be be be be be be be be be be'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34973bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7064937b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('epochBIG.h5') # larger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2aaa7f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(open('epochBIG','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "50e3359f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"at that stubb ' my frame roman eyes of his own power for the whale 's grain to wrenched progeny for a fever drawn up\""
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7839c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# going back to the previous model\n",
    "\n",
    "model = load_model('my_mobydick_model_08302022.h5') # larger model\n",
    "tokenizer = load(open('my_simpletokenizer_08302022','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f1bd7450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a bed and a harpooneer and a whale and be be be be be be be be be be be be be be be be'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = 'It is better to fail in originality than to succeed in' # imitation is what the actual word is \n",
    "# this is a quote by Herman Melville\n",
    "\n",
    "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc3456",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
